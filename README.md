# AWS_DeepRacer_RL_RobotCar

This repository contains the code and resources for training a robot car in AWS DeepRacer using reinforcement learning and participating in a race. AWS DeepRacer is a service that allows you to get started with reinforcement learning by training a virtual race car to navigate a simulated track. You can then deploy your trained model to a physical DeepRacer car and race it against other developers.

## Code Source and other ressources
The source code for this project is hosted externally due to its large size. You can access the code by following the link below:

https://drive.google.com/drive/folders/1WfuIEXaqCLEvToFHlgGpwhsqor03feCo?usp=sharing

## Reinforcement Learning
is a type of machine learning that enables an agent to learn through trial and error. In the context of AWS DeepRacer, the agent is the reinforcement learning model, and the environment is the simulated racetrack. The agent learns by taking actions (steering and throttle control), observing the results of those actions (the car's state), and receiving rewards (positive reinforcement for getting closer to the finish line, negative reinforcement for penalties).


## AWS DeepRacer 
is a fully autonomous 1/18th scale race car designed to test reinforcement learning models in a simulated racing environment. It provides a platform for developers, researchers, and enthusiasts to explore RL algorithms, train models, and compete in virtual and physical racing events. Through this project, I harness the power of DeepRacer to train my own model, enabling my robot car to navigate tracks autonomously and compete against other models.


## Resources

- AWS DeepRacer Website: https://aws.amazon.com/deepracer/
- AWS DeepRacer Getting Started Guide: https://docs.aws.amazon.com/deepracer/latest/developerguide/deepracer-get-started.html
- AWS DeepRacer Documentation: https://docs.aws.amazon.com/deepracer/
- AWS DeepRacer Student League: https://aws.amazon.com/deepracer/student/
